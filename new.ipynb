{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd974acd-9e0a-410d-b89c-e9a651b67381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1fee14-d3c7-4ef5-aaec-f5144fcd1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./kaggle_train_dataset.csv', sep=',',encoding='utf-8')\n",
    "df_test = pd.read_csv('./kaggle_test_dataset.csv', sep=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1909f6be-e856-4723-a053-88550d2fef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"content\"] = df_train[\"content\"].fillna(\"NoName\")\n",
    "df_test[\"content\"] = df_test[\"content\"].fillna(\"NoName\")\n",
    "df_train[\"title\"] = df_train[\"title\"].fillna(\"NoName\")\n",
    "df_test[\"title\"] = df_test[\"title\"].fillna(\"NoName\")\n",
    "df_train[\"text\"] = df_train.title + df_train.content\n",
    "df_test[\"text\"] = df_test.title + df_test.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4ea2ed-5fd9-416b-aef1-cfd9364ed677",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\charl\\NLP\\dict.txt.big ...\n",
      "Loading model from cache C:\\Users\\charl\\AppData\\Local\\Temp\\jieba.u84a06abc7f9e19dbe3099582e43bc074.cache\n",
      "Loading model cost 1.431 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>informative</td>\n",
       "      <td>本報特約----宏觀縱覽/溫家寶：當前重要的是促進投資合理增長</td>\n",
       "      <td>7月9日上午和10日上午，大陸國務院總理溫家寶先後主持召開兩次經濟形勢座談會，聽取專家和企業...</td>\n",
       "      <td>本報 特約 ---- 宏觀 縱覽 / 溫家寶 ： 當前 重要 的 是 促進 投資 合理 增長...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                            title  \\\n",
       "0  informative  本報特約----宏觀縱覽/溫家寶：當前重要的是促進投資合理增長   \n",
       "\n",
       "                                             content  \\\n",
       "0  7月9日上午和10日上午，大陸國務院總理溫家寶先後主持召開兩次經濟形勢座談會，聽取專家和企業...   \n",
       "\n",
       "                                                text  \n",
       "0  本報 特約 ---- 宏觀 縱覽 / 溫家寶 ： 當前 重要 的 是 促進 投資 合理 增長...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.set_dictionary(\"./dict.txt.big\")\n",
    "\n",
    "df_train[\"text\"] = df_train[\"text\"].astype(str).map(lambda x: \" \".join(jieba.cut(x, cut_all = False)))\n",
    "\n",
    "df_test[\"text\"] = df_test[\"text\"].astype(str).map(lambda x: \" \".join(jieba.cut(x, cut_all = False)))\n",
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6d347cc-860c-4ffc-8c43-4e2b73de43e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopwords=pd.read_table(\"./stopwords.txt\")\n",
    "lst_stopword=list(stopwords[\"是\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "243165fd-b234-4f08-990c-7f6e17cd2978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_preprocess_text(text,lst_stopwords=None):\n",
    "\n",
    " text = re.sub(r'[^\\u4e00-\\u9fa5]',\" \",str(text).strip())\n",
    " lst_text = text.split()    ## remove Stopwords\n",
    " if lst_stopwords is not None:\n",
    "    lst_text = [word for word in lst_text if word not in lst_stopword]\n",
    " text = \" \".join(lst_text)\n",
    " return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e96bdfe-5e07-4953-8750-4f6e4e0174a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>informative</td>\n",
       "      <td>本報特約----宏觀縱覽/溫家寶：當前重要的是促進投資合理增長</td>\n",
       "      <td>7月9日上午和10日上午，大陸國務院總理溫家寶先後主持召開兩次經濟形勢座談會，聽取專家和企業...</td>\n",
       "      <td>本報 特約 ---- 宏觀 縱覽 / 溫家寶 ： 當前 重要 的 是 促進 投資 合理 增長...</td>\n",
       "      <td>特約 宏觀 縱覽 溫家寶 重要 促進 投資 合理 增長 上午 上午 大陸 國務院 總理 溫家...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                            title  \\\n",
       "0  informative  本報特約----宏觀縱覽/溫家寶：當前重要的是促進投資合理增長   \n",
       "\n",
       "                                             content  \\\n",
       "0  7月9日上午和10日上午，大陸國務院總理溫家寶先後主持召開兩次經濟形勢座談會，聽取專家和企業...   \n",
       "\n",
       "                                                text  \\\n",
       "0  本報 特約 ---- 宏觀 縱覽 / 溫家寶 ： 當前 重要 的 是 促進 投資 合理 增長...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  特約 宏觀 縱覽 溫家寶 重要 促進 投資 合理 增長 上午 上午 大陸 國務院 總理 溫家...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"text_clean\"] = df_train[\"text\"].apply(lambda x: utils_preprocess_text(x,lst_stopwords=lst_stopword))\n",
    "\n",
    "df_test[\"text_clean\"] = df_test[\"text\"].apply(lambda x:utils_preprocess_text(x,lst_stopwords=lst_stopword))\n",
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "301f58f4-26e7-481c-9cb7-1d43c2fe28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = df_train[\"text_clean\"].values\n",
    "train_label = df_train[\"label\"].values\n",
    "TEST_features = df_test[\"text_clean\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ae5021-f9b5-4ca9-a430-c77488e688da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = train_features\n",
    "y_train = train_label\n",
    "x_TEST = TEST_features\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "classifier = ExtraTreesClassifier(n_estimators=200,class_weight = 'balanced_subsample')\n",
    "count_vectorizer = CountVectorizer(max_df=0.95,max_features=12000)\n",
    "\n",
    "# TF-IDF\n",
    "x_train_tfidf = count_vectorizer.fit_transform(x_train)\n",
    "x_TEST_tfidf = count_vectorizer.transform(x_TEST)\n",
    "classifier.fit(x_train_tfidf, y_train) \n",
    "\n",
    "# make predicitions\n",
    "TEST_predict_result = classifier.predict(x_TEST_tfidf)\n",
    "\n",
    "# transform label string to numbic due to Kaggle requirements.        \n",
    "str_encode_num = {'informative':0, 'happy':1, 'angry':2, 'depressing':3, 'odd':4, 'boring':5, 'warm':6,'worried':7}\n",
    "\n",
    "# output result to csv file\n",
    "with open(\"./kaggle_submission.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f'Id,Label\\n')\n",
    "    for idx, item in enumerate([str_encode_num[item] for item in TEST_predict_result]):\n",
    "        f.write(f'{idx},{item}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9338fc-baba-4b3f-a3fb-4a81f5eb43cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
